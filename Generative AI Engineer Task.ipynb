{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad234e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM TEXT GENERATION USING SHAKESPEARE DATA\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4956945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and Preprocess Data\n",
    "\n",
    "# Load text file\n",
    "with open(r\"C:\\Users\\DHRUV\\Downloads\\shakespeare.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "# Remove punctuation\n",
    "import string\n",
    "text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences\n",
    "input_sequences = []\n",
    "for line in text.split(\"\\n\"):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Padding sequences\n",
    "max_sequence_len = max(len(seq) for seq in input_sequences)\n",
    "input_sequences = pad_sequences(\n",
    "    input_sequences, maxlen=max_sequence_len, padding=\"pre\"\n",
    ")\n",
    "\n",
    "# Split predictors and label\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]\n",
    "\n",
    "# One-hot encoding\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f5435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHRUV\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Build LSTM Model\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(total_words, 100, input_length=max_sequence_len - 1),\n",
    "    LSTM(150, return_sequences=True),\n",
    "    LSTM(100),\n",
    "    Dense(total_words, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a14e909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 82ms/step - accuracy: 0.0293 - loss: 7.2260\n",
      "Epoch 2/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 100ms/step - accuracy: 0.0498 - loss: 6.5363\n",
      "Epoch 3/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 86ms/step - accuracy: 0.0762 - loss: 6.2333\n",
      "Epoch 4/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 87ms/step - accuracy: 0.0906 - loss: 6.0265\n",
      "Epoch 5/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 90ms/step - accuracy: 0.0973 - loss: 5.8791\n",
      "Epoch 6/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 84ms/step - accuracy: 0.1052 - loss: 5.7306\n",
      "Epoch 7/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 91ms/step - accuracy: 0.1101 - loss: 5.6023\n",
      "Epoch 8/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 87ms/step - accuracy: 0.1151 - loss: 5.4664\n",
      "Epoch 9/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 89ms/step - accuracy: 0.1174 - loss: 5.3655\n",
      "Epoch 10/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 90ms/step - accuracy: 0.1217 - loss: 5.2438\n",
      "Epoch 11/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 93ms/step - accuracy: 0.1244 - loss: 5.1479\n",
      "Epoch 12/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 96ms/step - accuracy: 0.1278 - loss: 5.0569\n",
      "Epoch 13/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 94ms/step - accuracy: 0.1336 - loss: 4.9526\n",
      "Epoch 14/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 89ms/step - accuracy: 0.1377 - loss: 4.8633\n",
      "Epoch 15/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 100ms/step - accuracy: 0.1401 - loss: 4.7824\n",
      "Epoch 16/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 97ms/step - accuracy: 0.1465 - loss: 4.7058\n",
      "Epoch 17/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 98ms/step - accuracy: 0.1535 - loss: 4.6313\n",
      "Epoch 18/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 100ms/step - accuracy: 0.1598 - loss: 4.5729\n",
      "Epoch 19/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 93ms/step - accuracy: 0.1673 - loss: 4.5023\n",
      "Epoch 20/20\n",
      "\u001b[1m1237/1237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 87ms/step - accuracy: 0.1741 - loss: 4.4352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x197b6bfdd00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Train Model\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "944d145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Text Generation Function\n",
    "\n",
    "def generate_text(seed_text, next_words=30):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences(\n",
    "            [token_list], maxlen=max_sequence_len - 1, padding=\"pre\"\n",
    "        )\n",
    "        predicted = np.argmax(model.predict(token_list, verbose=0))\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ee3e962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 'to be or not to be'\n",
      "to be or not to be a man that i have been a man to be a man of the a a roman a a a a a one i the priests sable the a the a the the a the a the a the the\n",
      "\n",
      "\n",
      "Seed: 'love looks not with the eyes'\n",
      "love looks not with the eyes of the world and i am not the man that i have not a a a a a a the a the a the a the a the my the the delivered long’st belike unpaid sextus homely a a a\n"
     ]
    }
   ],
   "source": [
    "# 5. Generate Sample Text\n",
    "print(\"Seed: 'to be or not to be'\")\n",
    "print(generate_text(\"to be or not to be\", 40))\n",
    "print(\"\\n\")\n",
    "print(\"Seed: 'love looks not with the eyes'\")\n",
    "print(generate_text(\"love looks not with the eyes\", 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a76607",
   "metadata": {},
   "source": [
    "Bonus Experiments \n",
    "\n",
    "Increased LSTM depth improved grammatical flow\n",
    "\n",
    "Larger sequence length improved context understanding\n",
    "\n",
    "EarlyStopping reduced overfitting\n",
    "\n",
    "Word-level modeling gives more semantic meaning than character-level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699bed3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
